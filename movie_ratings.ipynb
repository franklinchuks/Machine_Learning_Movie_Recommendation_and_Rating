{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Movie Genius!</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#link => https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata\n",
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert from json to strings\n",
    "movies['genres'] = movies['genres'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['genres']):\n",
    "    list1 = []\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'genres'] = str(list1)\n",
    "\n",
    "credits['cast'] = credits['cast'].apply(json.loads)\n",
    "for index,i in zip(credits.index,credits['cast']):\n",
    "    list1 = []\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    credits.loc[index,'cast'] = str(list1)\n",
    "\n",
    "credits['crew'] = credits['crew'].apply(json.loads)\n",
    "def director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "credits['crew'] = credits['crew'].apply(director)\n",
    "credits.rename(columns={'crew':'director'},inplace=True)\n",
    "\n",
    "movies['keywords'] = movies['keywords'].apply(json.loads)\n",
    "for index,i in zip(movies.index,movies['keywords']):\n",
    "    list1 = []\n",
    "    for j in range(len(i)):\n",
    "        list1.append((i[j]['name']))\n",
    "    movies.loc[index,'keywords'] = str(list1)\n",
    "\n",
    "#merging movies and credits df\n",
    "movies = movies.merge(credits,left_on='id',right_on='movie_id',how='left')\n",
    "\n",
    "#selecting only important columns\n",
    "movies = movies[['original_title', 'genres', 'cast', 'director', 'keywords', 'budget', 'revenue', 'vote_count', 'vote_average']]\n",
    "m = movies[['original_title', 'genres', 'cast', 'director', 'keywords', 'budget', 'revenue', 'vote_count', 'vote_average']]\n",
    "\n",
    "#rename title and rating column\n",
    "movies = movies.rename(columns={'original_title': 'title', 'vote_average': 'rating'})\n",
    "\n",
    "#remove []\n",
    "movies = movies[(movies[['genres', 'cast', 'director', 'keywords']] != '[]').all(axis=1) & (movies['rating'] != 0)].dropna()\n",
    "\n",
    "m = movies.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize\n",
    "import seaborn as sns\n",
    "\n",
    "#df for visualizations\n",
    "movies_visual = movies.dropna()\n",
    "\n",
    "#remove quotes from genres values\n",
    "movies_visual['genres'] = movies_visual['genres'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n",
    "movies_visual['genres'] = movies_visual['genres'].str.split(',')\n",
    "\n",
    "#bar plot of genres\n",
    "plt.subplots(figsize=(12, 6))\n",
    "list1 = []\n",
    "\n",
    "for i in movies_visual['genres']:\n",
    "    list1.extend(i)\n",
    "\n",
    "#bar colors\n",
    "ax = pd.Series(list1).value_counts()[:10].sort_values().plot.bar(width=0.5, color=sns.color_palette('husl', 10))\n",
    "\n",
    "#annotations\n",
    "for i, v in enumerate(pd.Series(list1).value_counts()[:10].sort_values().values):\n",
    "    ax.text(i, v + 0.1, str(v), fontsize=12, color='black', ha='center')\n",
    "\n",
    "#labels and title\n",
    "plt.xlabel('Genres')\n",
    "plt.ylabel('Movies')\n",
    "plt.title('Top 10 Genres')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove quotes and spaces from cast\n",
    "movies_visual['cast'] = movies_visual['cast'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'').str.replace('\"','')\n",
    "movies_visual['cast'] = movies_visual['cast'].str.split(',')\n",
    "\n",
    "#top actors bar chart\n",
    "plt.subplots(figsize=(12, 6))\n",
    "list1 = []\n",
    "\n",
    "for i in movies_visual['cast']:\n",
    "    list1.extend(i)\n",
    "\n",
    "# Use different colors from the 'husl' color palette\n",
    "ax = pd.Series(list1).value_counts()[:10].sort_values().plot.bar(width=0.5, color=sns.color_palette('husl', 10))\n",
    "\n",
    "# Add annotations\n",
    "for i, v in enumerate(pd.Series(list1).value_counts()[:10].sort_values().values):\n",
    "    ax.text(i, v + 0.1, str(v), fontsize=10, color='black', ha='center')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Actors')\n",
    "plt.ylabel('Movies')\n",
    "plt.title('Actors with Highest Appearance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directors chart\n",
    "plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Filter out rows where director is an empty string\n",
    "filtered_directors = movies_visual[movies_visual['director'] != '']\n",
    "\n",
    "ax = filtered_directors['director'].value_counts()[:10].sort_values().plot.bar(width=0.5, color=sns.color_palette('husl', 10))\n",
    "\n",
    "# Add annotations\n",
    "for i, v in enumerate(filtered_directors['director'].value_counts()[:10].sort_values().values):\n",
    "    ax.text(i, v + 0.1, str(v), fontsize=12, color='black', ha='center')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Directors')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Directors with Highest Movies')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a word cloud\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "plt.subplots(figsize=(12,12))\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(',',';','!','?','.','(',')','$','#','+',':','...',' ','')\n",
    "\n",
    "words=movies_visual['keywords'].dropna().apply(nltk.word_tokenize)\n",
    "\n",
    "word=[]\n",
    "for i in words:\n",
    "    word.extend(i)\n",
    "word=pd.Series(word)\n",
    "word=([i for i in word.str.lower() if i not in stop_words])\n",
    "wc = WordCloud(background_color=\"black\", max_words=100, stopwords=STOPWORDS, max_font_size= 100,width=1000,height=1000)\n",
    "wc.generate(\" \".join(word))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Exraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "m = movies.dropna()\n",
    "\n",
    "for col in ['genres', 'cast', 'director', 'keywords']:\n",
    "    m[col] = m[col].str.split(',').apply(lambda x: [i.strip('[]') for i in x])\n",
    "\n",
    "columns_to_process = ['genres', 'cast', 'director', 'keywords']\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "for column in columns_to_process:\n",
    "    m = m.join(pd.DataFrame(mlb.fit_transform(m.pop(column)),\n",
    "                                      columns=[f\"{column}_{class_}\" for class_ in mlb.classes_],\n",
    "                                      index=m.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Splitting into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = m['rating']\n",
    "X = m.drop(columns = ['rating', 'title'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>For movie recommendations with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model_knn.fit(X_train)\n",
    "\n",
    "def recommend_movies(x=0):\n",
    "    # Get the top 10 nearest neighbors for the movie\n",
    "    distances, indices = model_knn.kneighbors(X_train[x, :].reshape(1, -1), n_neighbors = 11)\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i == 0:\n",
    "            print(f\"Recommendations for {m['title'].iloc[x]}:\\n\")\n",
    "        else:\n",
    "            print(f\"{i}: {m['title'].iloc[indices.flatten()[i]]}, with distance of {round(distances.flatten()[i], 7)}\")\n",
    "\n",
    "recommend_movies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>For rating prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all machine learning tools and functions required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#predict a movie rating\n",
    "def predict_rating(i=0, model=knn, y_test = y_test):\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # Extract the features for the specified index\n",
    "    movie_features = X_test[i, :].reshape(1, -1)\n",
    "    predicted_rating = model.predict(movie_features)\n",
    "    actual_rating = m['rating'][i]\n",
    "    print(f\"For {model}:\")\n",
    "    print(f\"\\nPredicted rating for the movie {m['title'][i]} is {predicted_rating[0]:.2f}\")\n",
    "    print(f\"Actual Rating for the movie {m['title'][i]} is {actual_rating:.2f}\")\n",
    "    print(f'\\nWith a mean squared error of {mse:.2f} and mean absolute error of {mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "predict_rating()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "predict_rating(model=rf_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_regressor\n",
    "svm_regressor = SVR(kernel='linear')\n",
    "svm_regressor.fit(X_train, y_train)\n",
    "\n",
    "predict_rating(model=svm_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "predict_rating(model=linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge_model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "predict_rating(model=ridge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso_model\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "predict_rating(model=lasso_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "models = {\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100),\n",
    "    'SVM': SVR(kernel='linear'),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0)\n",
    "}\n",
    "\n",
    "# Perform k-fold cross-validation for each model\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=k_fold, scoring='neg_mean_squared_error')\n",
    "    mse_cv = -cv_scores.mean()\n",
    "    print(f'Cross-Validated MSE for {model_name}: {mse_cv:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Unsupervised Learning</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans clustering\n",
    "from sklearn.cluster import KMeans\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=5, random_state=1)\n",
    "cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to the original dataset\n",
    "data_with_clusters = pd.concat([pd.DataFrame(X), pd.Series(cluster_labels, name='Cluster')], axis=1)\n",
    "grouped_clusters = data_with_clusters.groupby('Cluster').mean()\n",
    "\n",
    "print(grouped_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphical visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Scatter plot for budget vs. revenue colored by cluster\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='revenue', y='budget', hue='Cluster', data=data_with_clusters, palette='viridis', hue_order=[0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "sns.regplot(x='revenue', y='budget', data=data_with_clusters, scatter=False, ci=None, color='orange')\n",
    "plt.title('Scatter Plot: Budget vs. Revenue by Cluster')\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Budget')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
